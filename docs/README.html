<h1 id="days-of-ml---log">100 Days Of ML - LOG</h1>
<p>My progress in the &quot;100 days of Machine Learning code challenge&quot;. That means coding and/or studying machine learning for at least an hour everyday for the next 100 days.</p>
<p> estas es una fucking prueba </p>
<h2 id="day-01-august-01-2018">Day 01 : August 01 , 2018</h2>
<p><strong>Today's Progress</strong> : I learned about probability spaces, events, random variables. And, I coded in Pandas.</p>
<p><strong>Thoughts</strong> : Hope this will be exiciting ,will help me in learning Machine Learning in a more effective way .</p>
<p><strong>Link of Work:</strong> <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%201%20-%20PandasBasics.ipynb">Commit</a></p>
<h2 id="day-02-august-02-2018">Day 02 : August 02 , 2018</h2>
<p><strong>Today's Progress</strong> : Reading about dependent and independent events, and marginal probability. I coded to simulate a probability.</p>
<p><strong>Thoughts</strong> : It's very useful to learn math for machine learning.</p>
<p><strong>Link of Work:</strong><br />- <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2002%20-%20Math%20lesson%201.ipynb">Commit - Probability 01</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2002%20-%20Math%20lesson%202.ipynb">Commit - Probability 02</a></p>
<h2 id="day-03-august-03-2018">Day 03 : August 03 , 2018</h2>
<p><strong>Today's Progress</strong> : Reading about the history of Data Visualization, and playing with matplotlib.pyplot.</p>
<p><strong>Link of Work:</strong> <a href="https://github.com/marbramen/100DaysOfMLCode/tree/master/Day%2003%20-%20Data%20Camp/Introduction%20to%20data%20visualization%20with%20python">Commit - Introduction to data visualization with python</a></p>
<h2 id="day-04-august-04-2018">Day 04 : August 04 , 2018</h2>
<p><strong>Today's Progress</strong> : I studied linear algebra: {tensors, matrices, eigenvalues, eigenvectors, single value decomposition} : Part 1.</p>
<p><strong>Thoughts</strong> : It's very useful to learn math for machine learning.</p>
<p><strong>Resources:</strong> Linear algebra - Gilber Strang. Data Driven Modeling &amp; Scientific computation, Methods for Complex Systems &amp; Big data - J. Nathan Kutz</p>
<h2 id="day-05-august-05-2018">Day 05 : August 05 , 2018</h2>
<p><strong>Today's Progress</strong> : A cursory reading for chapter 3 - Deep Learning book.</p>
<p><strong>Thoughts</strong> : I need more lectures and other resources for a full understanding.</p>
<p><strong>Link of Work:</strong> <a href="https://www.deeplearningbook.org/contents/prob.html">Probability and Information Theory - Deep Learning book</a></p>
<h2 id="day-06-august-06-2018">Day 06 : August 06 , 2018</h2>
<p><strong>Today's Progress</strong> : One hour more of Data Visualization. Playing with titanic tutorial - Kaggle, Part 1.</p>
<p><strong>Link of Work:</strong> - <a href="https://www.kaggle.com/rochellesilva/simple-tutorial-for-beginners/notebook">Simple tutorial for Beginners</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2006%20-%20Titanic%20-%20Tutorial.ipynb">Commit</a></p>
<h2 id="day-07-august-7-2018">Day 07 : August 7 , 2018</h2>
<p><strong>Today's Progress</strong> : Second lecture to chapter 3 Probability and Information Theory, Deep book.</p>
<p><strong>Thoughts</strong> : I need more resources.</p>
<p><strong>Link of Work:</strong> <a href="https://www.deeplearningbook.org/contents/prob.html">Probability and Information Theory - Deep Learning book</a></p>
<h2 id="day-08-august-08-2018">Day 08 : August 08 , 2018</h2>
<p><strong>Today's Progress</strong> : Discrete random variables, probability mass function, data visualization, data structures, data processing.</p>
<h2 id="day-091011-aug-09-aug-10-aug-11-2018">Day 09,10,11 : Aug 09, Aug 10, Aug 11 , 2018</h2>
<p><strong>Today's Progress</strong> : More of two hours by the three days: I read about data processing for data visualization, expectation, variance and covariance, and the final lecture of Chapter 3 of Deep Learning book.</p>
<p><strong>Link of Work:</strong> <a href="https://www.deeplearningbook.org/contents/prob.html">Probability and Information Theory - Deep Learning book</a></p>
<h2 id="day-12-august-12-2018">Day 12 : August 12 , 2018</h2>
<p><strong>Today's Progress</strong> :Reading machine learning frameworks, and playing with Tensorflow</p>
<p><strong>Link of Work:</strong> <a href="https://www.tensorflow.org/tutorials/">Tensorflow</a></p>
<h2 id="day-1314-aug-13-aug-14-2018">Day 13,14 : Aug 13, Aug 14 , 2018</h2>
<p><strong>Today's Progress</strong> : Learning and practicing: Python DataScience Handbook, chapter 5: What Is Machine Learning?, Scikit learn, Hyperparameters and Model Validation</p>
<p><strong>Thoughts</strong> : Lots and Lots of scikit, numpy code.</p>
<p><strong>Link of Work:</strong> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2013%2C14%2C15%2C18%2C19%2C20%20-%20Chapter%205%20-%20Machine%20Learning.ipynb">Commit</a> - <a href="https://jakevdp.github.io/PythonDataScienceHandbook/">Python Data Science Handbook</a></p>
<h2 id="day-15-aug-15-2018">Day 15 : Aug 15 , 2018</h2>
<p><strong>Today's Progress</strong> : Python DataScience Handbook, chapter 5: learning curves, grid search, feature engineering, text features.</p>
<p><strong>Thoughts</strong> : Having a good concept building in Maths is very important in ML .</p>
<ul>
<li><a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2013%2C14%2C15%2C18%2C19%2C20%20-%20Chapter%205%20-%20Machine%20Learning.ipynb">Commit</a></li>
<li><a href="https://jakevdp.github.io/PythonDataScienceHandbook/">Python Data Science Handbook</a></li>
</ul>
<h2 id="day-16-august-16-2018">Day 16 : August 16 , 2018</h2>
<p><strong>Today's Progress</strong> : My first submit to <a href="https://twitter.com/kaggle">@<strong>kaggle</strong></a>, I revised: Complete Beginner: Your First Titanic Submit and I coded a basic Autoencoder in <a href="https://twitter.com/TensorFlow">@<strong>TensorFlow</strong></a>.</p>
<h2 id="day-17-august-17-2018">Day 17 : August 17 , 2018</h2>
<p><strong>Today's Progress</strong> : Day 17: A little reading of the The Book of Why by Judea Pearl, a new theory of causality. I watched the video lecture 01 of MOOC FastAI.</p>
<p><strong>Link of Work:</strong> <a href="https://t.co/5n4SUAJyw7" title="http://fast.ai">fast.ai</a></p>
<h2 id="day-1819-aug-18-aug-19-2018">Day 18,19 : Aug 18, Aug 19 , 2018</h2>
<p><strong>Today's Progress</strong> : I implemented a two basic autoencoder, intermediate level autoencoder.</p>
<p><strong>Thoughts</strong> : Autoencoder is pretty amazing.</p>
<p><strong>Link of Work:</strong> - <a href="">Commit - Basic Autoencoder 01</a> - <a href="">Commit - Basic Autoencoder 02</a> - <a href="">Commit - Intermediate Autoencoder 03</a></p>
<h2 id="day-20-august-20-2018">Day 20 : August 20 , 2018</h2>
<p><strong>Today's Progress</strong> : Reading about linear regression, multinomial Naive Bayes :)</p>
<p><strong>Thoughts</strong> : Multinomial Naive Bayes trick is really a tricky concept . Have to read more of it . And again math is very much important for ML.</p>
<p><strong>Link of Work:</strong> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2013%2C14%2C15%2C18%2C19%2C20%20-%20Chapter%205%20-%20Machine%20Learning.ipynb">Commit</a> - <a href="https://jakevdp.github.io/PythonDataScienceHandbook/">Python Data Science Handbook</a></p>
<h2 id="day-21-august-21-2018">Day 21 : August 21 , 2018</h2>
<p><strong>Today's Progress</strong> : Video lectures of Calculus <a href="https://twitter.com/hashtag/3Blue1Brown?src=hash">#<strong>3Blue1Brown</strong></a>. I read about basic concepts of supervised learning, unsupervised learning, and ANN.</p>
<p><strong>Link of Work:</strong> - <a href="https://www.youtube.com/watch?v=WUvTyaaNkzM&amp;list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr&amp;index=1">Video Lecture - # Essence of calculus, chapter 1</a> - <a href="https://www.youtube.com/watch?v=9vKqVkMQHKk&amp;list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr&amp;index=2">Video Lecture - # The paradox of the derivative | Essence of calculus, chapter 2</a> - <a href="https://www.youtube.com/watch?v=S0_qX4VJhMQ&amp;list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr&amp;index=3">Video Lecture - # Derivative formulas through geometry | Essence of calculus, chapter 3</a> - <a href="https://brilliant.org/">brilliant.org</a></p>
<h2 id="day-22-august-22-2018">Day 22 : August 22 , 2018</h2>
<p><strong>Today's Progress</strong> :Coding with nltk for NLP. Reading calculus for machine learning, and practicing exercises of expectation and variance.</p>
<p><strong>Link of Work:</strong> <a href="http://www.nltk.org/book/">Natural Language Processing with Python</a></p>
<h2 id="day-23-august-23-2018">Day 23 : August 23 , 2018</h2>
<p><strong>Today's Progress</strong> : Practicing calculus. My first convNet in Pytorch.</p>
<p><strong>Link of Work:</strong> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2023%20-%20Pytorch%20Neural%20Network.ipynb">Commit</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2023%20-%20Tutorial%20Pytorch.ipynb">Commit</a> - <a href="https://archive.org/details/ost-math-33283-pdf">Calculus Made Easy by Silvanus P. Thompson</a></p>
<h2 id="day-24-august-24-2018">Day 24 : August 24 , 2018</h2>
<p><strong>Today's Progress</strong> : Installation of Keras with Theano backend. Implementation of a basic multilayer perceptron.</p>
<p><strong>Thoughts</strong> : Configuration of frameworks isn't always easy.</p>
<p><strong>Link of Work:</strong> <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2024%20-%20Keras%20Basic.ipynb">Commit</a></p>
<h2 id="day-25-august-25-2018">Day 25 : August 25 , 2018</h2>
<p><strong>Today's Progress</strong> : I read information theory - chapter 3 of the Deep Learning book</p>
<p><strong>Link of Work:</strong><a href="https://www.deeplearningbook.org/contents/prob.html">Probability and Information Theory - Deep Learning book</a></p>
<h2 id="day-26-august-26-2018">Day 26 : August 26 , 2018</h2>
<p><strong>Today's Progress</strong> : Coding Principal Component Analysis step by step in numpy.</p>
<p><strong>Link of Work:</strong> <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2026%20-%20Principal%20Component%20Analysis.ipynb">Commit</a></p>
<h2 id="day-27-august-27-2018">Day 27 : August 27 , 2018</h2>
<p><strong>Today's Progress</strong> : Lesson 01 - Recognizing dogs and cats - FastAI. Coding a basic perceptron in numpy.</p>
<p><strong>Thoughts</strong> : Concepts are really good.</p>
<p><strong>Link of Work:</strong> - <a href="http://course.fast.ai/lessons/lesson1.html">Lesson 1 Recognizing cats and dogs</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2027%20-%20Very%20Basic%20Perceptron.ipynb">Commit</a></p>
<h2 id="day-28-august-28-2018">Day 28 : August 28 , 2018</h2>
<p><strong>Today's Progress</strong> : Coding a basic Support Vector Machine with Hinge loss function for 2d data.</p>
<p><strong>Thoughts</strong> : SVM is fancy.</p>
<p><strong>Link of Work:</strong> <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2028%20-%20Support%20Vector%20Machine%20Step%20by%20Step.ipynb">Commit</a></p>
<h2 id="day-29-august-29-2018">Day 29 : August 29 , 2018</h2>
<p><strong>Today's Progress</strong> : Reading about visualization techniques: scatter plot matrix, GPlom, multidimensional projections, RadViz, concetric radviz, parallel coordinates, parallel set, Star coordinates, IStar.</p>
<p><strong>Thoughts</strong> : data visualization is a beauty.</p>
<p><strong>Link of Work:</strong> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day_29_01.html">Commit</a> - <a href="https://d3js.org/">d3js</a></p>
<h2 id="day-30-august-30-2018">Day 30 : August 30 , 2018</h2>
<p><strong>Today's Progress</strong> : In Depth - Support Vector Machine, Python Data Science Handbook book, Jake VanderPlas</p>
<p><strong>Thoughts</strong> : very good concepts.</p>
<p><strong>Link of Work:</strong> - <a href="https://jakevdp.github.io/PythonDataScienceHandbook/">Python Data Science Handbook</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2030%20-%20Chapter%205%20-%20Machine%20Learning.ipynb">Commit</a></p>
<h2 id="day-3132-aug-31-sep-01-2018">Day 31,32 : Aug 31, Sep 01 , 2018</h2>
<p><strong>Today's Progress</strong> : I read Numerical Computation, chapter 4 at deep learning book. Programming an embedding layer in keras, for IMDB dataset</p>
<p><strong>Link of Work:</strong> - <a href="https://www.deeplearningbook.org/contents/numerical.html">4 Numerical Computation - Deep Learning Book</a> - <a href="https://www.manning.com/books/deep-learning-with-python">Manning | Deep Learning with Python</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2031%2C32%20-Deep%20Learning%20for%20text%20and%20sequences%20-%20Deep%20Learning%20with%20python.ipynb">Commit</a></p>
<h2 id="day-3334-sep-02-sep-03-2018">Day 33,34 : Sep 02, Sep 03 , 2018</h2>
<p><strong>Today's Progress</strong> : Tweet tokenizer and word2vec model.</p>
<p><strong>Link of Work:</strong> <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2033%20-%20Sentiment%20Analysis%20-%20Part%201.ipynb">Commit</a></p>
<h2 id="day-3536-sep-04-sep-05-2018">Day 35,36: Sep 04, Sep 05 , 2018</h2>
<p><strong>Today's Progress</strong> : IMDB model with/without pretrained word embeddings. It implemented in Keras.</p>
<p><strong>Thoughts</strong>: Keras is very easy to build neuronal models.</p>
<p><strong>Link of Work:</strong> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2035%2C36%20-Deep%20Learning%20for%20text%20and%20sequences%20-%20Deep%20Learning%20with%20python-Copy1.ipynb">Commit</a> - <a href="https://jakevdp.github.io/PythonDataScienceHandbook/">Python Data Science Handbook</a></p>
<h2 id="day-37-september-06-2018">Day 37: September 06, 2018</h2>
<p><strong>Today's Progress</strong>: Implementation of a simple recurrent neural network in Keras. Coding a linear regression in numpy. Solving quiz 1 of How to Win a Data Science Competition course.</p>
<p><strong>Thoughts</strong>: Keras is a easy-to-use library for developing a neuronal model.</p>
<p><strong>Link of Work:</strong> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2037%20-%20Simple%20recurrent%20neural%20networks.ipynb">Commit - Simple Recurrent Neural Network</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2037%20-%20Linear%20Regression%20%26%20PCA.ipynb">Commit - Linear Regression &amp; PCA</a> - <a href="https://www.coursera.org/learn/competitive-data-science/home/welcome">How to Win a Data Science Competition</a></p>
<h2 id="day-3839-sep-07-sep-08-2018">Day 38,39: Sep 07, Sep 08, 2018</h2>
<p><strong>Today's Progress</strong>: Attended meetup Deep Learning Book Chapter 5 Part I. Solving integral math exercises. Coding a GRU, LSTM, BiLSTM, BiGRU for IMDB.</p>
<p><strong>Link of Work:</strong> - <a href="https://www.youtube.com/watch?v=PZUnobWpK8M">Meetup: Deep Learning Book Chapter 5 Part I</a> - <a href="https://archive.org/details/ost-math-33283-pdf">Calculus Made Easy by Silvanus P. Thompson</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2038%20-%20Comparasion%20between%20LSTM%2C%20GRU%2C%20BiLSTM%20in%20Keras.ipynb">Commit</a></p>
<h2 id="day-40-sep-10-2018">Day 40: Sep 10, 2018</h2>
<p><strong>Today's Progres</strong>: Reading about differential equations and infinite series.</p>
<p><strong>Link of Work:</strong> - <a href="https://archive.org/details/ost-math-33283-pdf">Calculus Made Easy by Silvanus P. Thompson</a></p>
<h2 id="day-4142-sep-10-sep-11-2018">Day 41,42: Sep 10, Sep 11, 2018</h2>
<p><strong>Today's Progress</strong>: Text classification with CNN + GRU + pre-trained GloVe embeddings models. And visualizations of word embeddings. With a small math integrals reading.</p>
<p><strong>Link of Work:</strong> <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2041%2C42%20-%20Data%20Processing%2C%20CNN%2BBiGRU%2Bword%20embeddiins%20pretrained.%20for%20text%20classification.ipynb">Commit - Data Processing, CNN+BiGRU+word embeddiins pretrained. for text classification</a></p>
<h2 id="day-43-september-12-2018">Day 43: September 12, 2018</h2>
<p><strong>Today's Progress</strong>: Solving covariance and correlation math exercises. Coding a correlation program. Understanding Neural Machine Translation toolkit.</p>
<p><strong>Link of Work:</strong> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2043%20-%20Correlation.ipynb">Commit - Correlation</a> - <a href="https://github.com/tensorflow/nmt">Neural Machine Translation (seq2seq) Tutorial</a></p>
<h2 id="day-44-september-13-2018">Day 44: September 13, 2018</h2>
<p><strong>Today's Progress</strong>: Reading about Kaggle's data science competitions.</p>
<p><strong>Link of Work:</strong> <a href="https://www.kaggle.com/">Kaggle</a></p>
<h2 id="day-4546-sep-14-sep-15-2018">Day 45,46: Sep 14, Sep 15, 2018</h2>
<p><strong>Today's Progress</strong>: Chapter 5 - Machine Learning Basics - Deep Learning Book</p>
<p><strong>Link of Work:</strong> <a href="https://www.deeplearningbook.org/contents/ml.html">Chapter 5 DLB</a></p>
<h2 id="day-4748-sep-16-sep-17-2018">Day 47,48: Sep 16, Sep 17, 2018</h2>
<p><strong>Today's Progress</strong>: Reading about index of machine learning, artificial intelligence, data science books, and reading the syllabus of MOOCS about machine learning or deep learning. For making my own ML syllabus</p>
<h2 id="day-49-september-18-2018">Day 49: September 18, 2018</h2>
<p><strong>Today's Progress</strong>: Coding visualizations with D3.</p>
<p><strong>Link of WorK:</strong> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2049%20-%20D3%20Code02%20-%20general%20zoom.html">Commit - D3 - general zoom</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2050%20-%20D3%20Code01%20-%20specificZoom_drag.html">Commit - D3 - specific zoom and drag</a> - <a href="https://bost.ocks.org/mike/">Mike Bostock- Visualizations</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2049%20-%20D3%20Code03%20-%20drag.html">Commit - D3 - drag</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2049%20-%20D3%20Code04%20-%20drag%20and%20general%20zoom.html">Commit - D3 - drag and general zoom</a></p>
<h2 id="day-50-september-19-2018">Day 50: September 19, 2018</h2>
<p><strong>Today's Progress</strong>: Reading and coding about Naive Bayes, part I.</p>
<p><strong>Link of Work:</strong> <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2050%20-%20Naive%20Bayes.ipynb">Commit Naive Baye</a></p>
<h2 id="day-51-september-20-2018">Day 51: September 20, 2018</h2>
<p><strong>Today's Progress</strong>: Reading and coding about Naive Bayes with Gaussian Densidity Function.</p>
<p><strong>Link of Work:</strong> <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2051%20-%20Naive%20Bayes%20with%20Gaussian%20Density%20Function.ipynb">Commit Naive Baye with Gaussian Probability</a></p>
<h2 id="day-52-september-21-2018">Day 52: September 21, 2018</h2>
<p><strong>Today's Progress</strong>: Reading about CS229 Lectures Notes - Generative Learning Algorithms. Watch Naive Bayes' video lectures by Andrew Ng.</p>
<p><strong>Link of Work:</strong> - <a href="http://cs229.stanford.edu/notes/cs229-notes2.pdf">Part IV Generative Learning algorithms-Andrew Ng</a> - <a href="https://www.youtube.com/watch?v=z5UQyCESW64">Video lecture - Andrew Ng Naive Bayes Generative Learning Algorithms</a> - <a href="https://www.youtube.com/watch?v=NFd0ZQk5bR4">Andrew Ng Naive Bayes Text Clasification</a></p>
<h2 id="day-53-september-22-2018">Day 53: September 22, 2018</h2>
<p><strong>Today's Progress</strong>: Chapter 6 - Deep Feedforward Networks - Deep Learning Book.</p>
<p><strong>Link of Work:</strong> <a href="https://www.deeplearningbook.org/contents/mlp.html">Chapter 6 Deep Feedforward Networks</a></p>
<h2 id="day-54-september-23-2018">Day 54: September 23, 2018</h2>
<p><strong>Today's Progress</strong>: Streaming tutorial of temporal series. Learning about lag function, Simple Moving Average(SMA), Weighted Moving Average (WMA), White Noise, transformations of temporal series.</p>
<p><strong>Thoughts</strong>: Understanding the time's influence is awesome.</p>
<p><strong>Link of Work:</strong> <a href="https://www.youtube.com/watch?v=DbW3VvCtOhY">Tutorial: Time Series Analysis</a></p>
<h2 id="day-55-september-24-2018">Day 55: September 24, 2018</h2>
<p><strong>Today's Progress</strong>: Making a presentation about Naive Bayes &amp; Bayes Classifier</p>
<p><strong>Thoughts</strong>: The best learning is to teach..</p>
<p><strong>Link of Work:</strong> <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2055%20Lesson%2002%20-%20Bayes%20%26%20Naive%20Bayes.pdf">Commit Naive Bayes&amp; Bayes Classifier Presentation</a></p>
<h2 id="day-56-september-25-2018">Day 56: September 25, 2018</h2>
<p><strong>Today's Progress</strong>: Improvements to my presentation about Naive Bayes &amp; Bayes Classifier. Coding Naive Bayes with Scikit Learn. Refactor my scratch Gaussian Naive Bayes.</p>
<p><strong>Thoughts</strong>: The best learning is to teach.</p>
<p><strong>Link of Work:</strong> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2055%20Lesson%2002%20-%20Bayes%20%26%20Naive%20Bayes.pdf">Commit Naive Bayes&amp; Bayes Classifier Presentation</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2056%20-%20Naive%20Bayes%20with%20Scikit%20Learn.ipynb">Naive Bayes witk Scikit Learn</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2051%20-%20Naive%20Bayes%20with%20Gaussian%20Density%20Function.ipynb">Commit Gaussian Naive Baye</a></p>
<h2 id="day-57-september-26-2018">Day 57: September 26, 2018</h2>
<p><strong>Today's Progress</strong>: Assignment 01 - Part I of course cs224-NLP with Deep Learning.</p>
<p><strong>Thoughts</strong>: The course is great.</p>
<p><strong>Link of Work:</strong> - <a href="http://web.stanford.edu/class/cs224n/assignment1/index.html">Assignment 01</a></p>
<h2 id="day-5859-sep-2728-2018">Day 58,59: Sep 27,28, 2018</h2>
<p><strong>Today's Progress</strong>: Reading paper &quot;Online and Linear-Time Attention by Enforcing Monotonic Alignments&quot; by Colin Raffel. Reading about Bayes Network, I played with WEKA.</p>
<p>** Thoughts**: Playing with machine learning in WEKA was funny.</p>
<p><strong>Link of Work:</strong> - <a href="https://arxiv.org/abs/1704.00784">Online and Linear-Time Attention by Enforcing Monotonic Alignments by Raftel</a> - <a href="http://web.ydu.edu.tw/~alan9956/docu/refer/BayesWEKA.pdf">A Tutorial on Bayesian cla/ssifier A Tutorial on Bayesian classifier with WEKA</a></p>
<h2 id="day-60-september-29-2018">Day 60: September 29, 2018</h2>
<p><strong>Today's Progress</strong>: Meetup Chapter 7 Deep Learning Book.</p>
<p><strong>Link of Work:</strong> - <a href="https://www.deeplearningbook.org/contents/regularization.html">Chapter 7 Deep Learning Book</a> - <a href="https://www.youtube.com/watch?v=NzkuFAzFjGM">Meetp up - Chapter 7 Deep Learning Book - Part I</a> - <a href="https://www.youtube.com/watch?v=YzDBpYUL-uQ">Meetp up - Chapter 7 Deep Learning Book - Part II</a></p>
<h2 id="day-6162-sep-30-oct-01-2018">Day 61,62: Sep 30, Oct 01, 2018</h2>
<p><strong>Today's Progress</strong>: Reading kernel notebook of data competition in Kaggle. Solving the first assignment of mlcourse.ai.</p>
<p><strong>Thoughts</strong>: Better late than never. I will commit the first assignment after of October 14.</p>
<p><strong>Link of Work:</strong> - <a href="https://www.kaggle.com/c/bbvadatachallenge-recomendador">Data Science Competition</a> - <a href="https://github.com/Yorko/mlcourse.ai/blob/master/jupyter_english/assignments_fall2018/assignment1_pandas_olympic.ipynb">First Assignment mlcourse.ai</a></p>
<h2 id="day-63-october-02-2018">Day 63, October 02, 2018</h2>
<p><strong>Today's Progress</strong>: Assignment01 - Part II of course cs224-NLP with Deep Learning. Implementing a Multi Layer Perceptron with numpy.</p>
<p><strong>Thoughts</strong>: Better late than never.</p>
<p><strong>Link of Work:</strong> - <a href="http://web.stanford.edu/class/cs224n/assignment1/index.html">Assignment 01</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/tree/master/NLP%20with%20Deep%20Learning">Commit Assigment 01 Part II</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2063%20-%20Multi%20Layer%20Perceptron.ipynb">Commit MLP in numpy</a></p>
<h2 id="day-6465-oct-0304-2018">Day 64,65, Oct 03,04, 2018</h2>
<p><strong>Today's Progress</strong>: Making a basic presentation of Bayesian Network, basic level. Streaming paper review - Reducing the Dimensionality of Data with Neural Networks.</p>
<p><strong>Thoughts</strong>: The best learning is to teach.</p>
<p><strong>Link of Work:</strong> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2064%20-%20Bayes%20Network.pdf">Commit presentation - Bayes Network - Version 1.0</a> - <a href="https://www.youtube.com/watch?v=eAQsrtPzufM">Paper review</a> - <a href="https://www.cs.toronto.edu/~hinton/science.pdf">Reducing the Dimensionality of Data with Neural Networks</a></p>
<h2 id="day-66-october-05-2018">Day 66 October 05, 2018</h2>
<p><strong>Today's Progress</strong>: Reading chapter 14 Probabilistic Reasoning - Artificial Intelligence: A Modern Approach by Russel &amp; Norvig</p>
<p><strong>Link of Work:</strong> - <a href="http://aima.cs.berkeley.edu/">Artificial Intelligence: A Modern Approach</a></p>
<h2 id="day-6768-oct-0607-2018">Day 67,68 Oct 06,07 , 2018</h2>
<p><strong>Today's Progress</strong>: Reading all chapter 14 Probabilistic Reasoning - Artificial Intelligence: A Modern Approach by Russel &amp; Norvig. Improving my presentation about Bayesian Network</p>
<p><strong>Link of Work:</strong> - <a href="http://aima.cs.berkeley.edu/">Artificial Intelligence: A Modern Approach</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2064%2C68%20-%20Bayes%20Network.pdf">Commit presentation - Bayes Network - Version 2.1</a></p>
<h2 id="day-69-october-08-2018">Day 69 October 08, 2018</h2>
<p><strong>Today's Progress</strong>: Practicing bayesian network exercises. Finishing my presentation about Bayesian Network.</p>
<p><strong>Link of Work:</strong> - <a href="http://aima.cs.berkeley.edu/">Artificial Intelligence: A Modern Approach</a> - <a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2069%20-%20Bayes%20Network.pdf">Commit presentation - Bayes Network - Version 2.2</a> - <a href="https://imada.sdu.dk/~marco/DM825/Assignments/sheet12.pdf">Bayesian exercises I</a> - <a href="https://www.mimuw.edu.pl/~noble/BNshortanswers.pdf">Bayesian exercises II</a></p>
<h2 id="day-7071-oct-0910-2018">Day 70,71, Oct 09,10, 2018</h2>
<p><strong>Today's Progress</strong>: Attending classes about Hidden Markov Model and Viterbi Algorithm. Completing the first assignment of mlcourse.ai.</p>
<p><strong>Thoughts</strong>: The course is great. HMM isn't so complicated.</p>
<p><strong>Link of Work:</strong> - <a href="https://github.com/jose2008/ucspdatasciencegroup/blob/master/subject/machine%20Learning/Lesson%2003%20-%20HMM.pdf">Hidden Markov Model- Jenny Copara</a></p>
<h2 id="day-72-october-11-2018">Day 72, October 11, 2018</h2>
<p>** Today's Progress**: Looking AI internship.</p>
<p><strong>Thoughts</strong>: It's not impossible, get a internship.</p>
<p><strong>Link of Work:</strong></p>
<ul>
<li><a href="https://www.youtube.com/watch?v=CGTn0ceOaOM">Siraj Raval - How to get a Intershi</a></li>
<li><a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/List%20of%20AI%20Residencies%20Programs.ipynb">Commit - List of residency program</a></li>
</ul>
<h2 id="day-7374-oct-1718-2018">Day 73,74, Oct 17,18, 2018</h2>
<p>** Today's Progres**: Week 2, Part I, Exploration Data Analysis, How to win data science competition? Watching video lectures about K-fold, holdout, leave of one, split time, validation, stratification, etc. Commit the first assignment of mlcourse.ai</p>
<p><strong>Link of Work:</strong></p>
<ul>
<li><a href="https://www.coursera.org/learn/competitive-data-science/home/week/2">Week 2-How to win data science competition</a></li>
<li><a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2071%20-%20mlcourse.ai%20-%20assignment%201%20-%20pandas%20olympic.ipynb">Commit</a></li>
</ul>
<h2 id="day-75-october-23-2018">Day 75, October 23, 2018</h2>
<p>** Today's Progress**: Sentiment Analysis in tensorflow. Imdb data set.</p>
<p><strong>Link of Work:</strong></p>
<ul>
<li><a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2075%20-%20Sentiment%20Analysis%20in%20Tensorflow.ipynb">Commit SA in tensorflow</a></li>
</ul>
<h2 id="day-76777879-october-25262829.-2018">Day 76,77,78,79, October 25,26,28,29. 2018</h2>
<p>** Progress**: Stack LSMT model for Sentiment Analysis in TensorFlow, using IMDB data set. Word level language modeling for coco-val-annotations, using TensorFlow.</p>
<p><strong>Link of Work:</strong></p>
<ul>
<li><a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2076%20-%20Stack%20LSTM%20-%20%20Sentiment%20Analysis%20in%20Tensorflow.ipynb">Commit Stack LSTM SA in TensorFlow</a></li>
<li><a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2077%2C78%2C79%20-%20Word%20Level%20Language%20Modeling%20in%20TensorFlow.ipynb">Commit Word Level Language Modeling in TensorFlow</a></li>
</ul>
<h2 id="day-8081-november-2021.-2018">Day 80,81, November 20,21. 2018</h2>
<p>** Progress**: Code of Decision Tree &amp; Random Forest with Scikit Learn. Making a presentation about Decision Tree &amp; Random Forest.</p>
<p><strong>Link of Work:</strong></p>
<ul>
<li><a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2080%20-%20Decision%20Tree%20%26%20Random%20Forest.ipynb">Commit Decision Tree &amp; Random Forest</a></li>
<li><a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2080%2C81%20-%20Decision%20Tree%20Presentation.pdf">Presentation Decision Tree &amp; Random Forest</a></li>
</ul>
<h2 id="day-8283-november-2324.-2018">Day 82,83, November 23,24. 2018</h2>
<p>** Progress**: Reading Chapter 10 - Part I of Deep Learning Book. Making a presentation of Chapter 10 - Part I of Deep Learning Book.</p>
<p><strong>Link of Work:</strong></p>
<ul>
<li><a href="https://www.deeplearningbook.org/contents/rnn.html">Chapter 10 DLB</a></li>
<li><a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2082%20-%20Chapter%2010%20Part%20I%20-%20DLB.pdf">Commit - Presentation Chapter 10 Part I</a></li>
</ul>
<h2 id="day-84-november-28-2018">Day 84, November 28, 2018</h2>
<p>** Progress**: Video lectures week 3 (Metrics Optimizatiom), of course How to Win a Data Science Competition: Learn from Top Kagglers.</p>
<p><strong>Link of Work:</strong></p>
<ul>
<li><a href="https://www.coursera.org/learn/competitive-data-science/home/week/3">How to Win a Data Science Competition - Week3</a></li>
</ul>
<h2 id="day-8586-november-2930-2018">Day 85,86, November 29,30, 2018</h2>
<p>** Progress**: Reading Chapter 10 - Part II of Deep Learning Book. Making a presentation of Chapter 10 - Part I of Deep Learning Book.</p>
<p><strong>Link of Work:</strong></p>
<ul>
<li><a href="https://www.deeplearningbook.org/contents/rnn.html">Chapter 10 DLB</a></li>
<li><a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2085%2C86%20-%20Chapter%2010%20Part%20II%20-%20DLB.pdf">Commit - Presentation Chapter 10 Part II</a></li>
</ul>
<h2 id="day-87-december-1-2018">Day 87, December 1, 2018</h2>
<p>** Progress**: Meetup about Support Vector Machine(SVM), linearly separable, almost linearly separable, not linearly separable, kernels.</p>
<p><strong>Link of Work:</strong></p>
<ul>
<li>Onsite meetup.</li>
</ul>
<h2 id="day-88-december-8-2018">Day 88, December 8, 2018</h2>
<p>** Progress**: Meetup about Chapter 11 of Deep Learning Book - Practical Methodology.</p>
<p><strong>Link of Work:</strong></p>
<ul>
<li><a href="https://www.youtube.com/watch?v=nzLqmSu6fJU">Online meetup</a></li>
<li><a href="https://www.deeplearningbook.org/contents/guidelines.html">Chapter 11 DLB</a></li>
</ul>
<h2 id="day-89-december-15-2018">Day 89, December 15, 2018</h2>
<p>** Progress**: Meetup about Chapter 12 of Deep Learning Book - Applications.</p>
<p><strong>Link of Work:</strong></p>
<ul>
<li>Onsite meetup</li>
<li><a href="https://www.deeplearningbook.org/contents/applications.html">Chapter 12 DLB</a></li>
</ul>
<h2 id="day-9091929394959697-january-01-10-2019">Day 90,91,92,93,94,95,96,97, January 01-10, 2019</h2>
<p>** Progress**: Making a presentation: &quot;Tutorial Deep Learning for Natural Language Processing&quot; for First Peruvian Symposium of Deep Learning. Organizer full time for First Peruvian Symposium of Deep Learning, Arequipa, Peru, 2019. In this tutorial, we will learn some concepts of deep learning for natural language processing. We will approach the most important concepts such as word embedding and recurrent neural networks. Some of the topics are: Natural Language Processing, Word Embedding, Recurrent Neural Network, Long Short Term Memory, Gated Recurrent Unit, Bi-RNN, Recursive Neural Networks, Stack RNN, Language Modeling, Sentiment Analysis, Named Entity Recognition(NER), Opinion Mining, Attention/self-Attention, Machine Translation, Question Answering, Visual Question Answering, Transfer Learning in NLP.</p>
<p><strong>Thoughts</strong>: The best learning is to teach.</p>
<p>** Link of Work:</p>
<ul>
<li><a href="https://sites.google.com/view/spdl-2019/">I Peruvian Symposium of Deep Learning</a></li>
<li><a href="https://github.com/marbramen/100DaysOfMLCode/blob/master/Day%2091%2C92%2C93%2C94%2C95%2C96%2C97%20Tutorial%20Deep%20Learning%20for%20Natural%20Language%20Processing.pdf">Tutorial Deep Learning for Natural Language Processing</a></li>
</ul>
<h2 id="day-9899100-janaury-101112-2019">Day 98,99,100, Janaury 10,11,12, 2019</h2>
<p>** Progress**: Attendance, speaker and organizer in the I Peruvian Symposium of Deep Learning, Arequipa, Peru</p>
<p><strong>Thoughts</strong>: The best learning is to teach.</p>
<p>**Link of Work:</p>
<ul>
<li><a href="https://sites.google.com/view/spdl-2019/">I Peruvian Symposium of Deep Learning</a></li>
<li><a href="https://sites.google.com/view/spdl-2019/diapositivas">Lectures-expositions</a></li>
<li><a href="https://www.facebook.com/events/2003452196408936/">facebook event</a></li>
</ul>
